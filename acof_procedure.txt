#pragma TextEncoding = "UTF-8"
#pragma rtGlobals=3		// Use modern global access method and strict wave access.
#include <kill waves>


function global_variables()
	variable/g num_runs, num_rotations, max_score, num_bins
	variable/g sig_min, sig_max, threshold
	variable/g dV, S
	
	wave allData
	num_runs = dimsize(allData,0)
	num_rotations = 26
	max_score = 1.0
	num_bins=30 //KWM
	
	sig_min = -195
	sig_max = -155
	threshold = -172

	dV=-3.21222 // from calibrate_readout()
	S=0.414987

end //global_variables


function main()
	// LOAD DATA
	//string file_path = "Macintosh HD:Users:jmonroe:Documents:research:projects:arrowOfTime_feedback:dataAnalysis"
	string file_path = "C:Data:2018:Reversed_Feedback:data_run3:v3_gooder" 
	string file_name = "fullData_rev_26Rot_-0.45,0.35Amp_5446Start_145nsInteg_f1.5_xyzTomo_p1"
	
	LoadWave/O/G/Q/M/D/N=allData file_path + ":" + file_name
	wave allData0//, allData // allData = [angle_sweep x (27 pnts), angle_sweep y, angle_sweep z] x10^4	
	duplicate/O allData0 allData //rename doesn't have an overwrite option
	matrixtranspose allData // don't need this when data is saved with "save_1d2d.vi"

	// CHECK DATA
//	decompose_sequence(allData) // double check Alazar readout
	wave corrTomo_x, corrTomo_y, corrTomo_z, counts_x, counts_y, counts_z
	check_corrTomo(allData) 

	calibrate_readout() // use this to calcuate offsets/scaling (by hand)
	wave corrTomo_z_c, corrTomo_x_c
	scale_tomo_for_readout_fidelity()
	wave z_theory,x_theory
	make_theoryCurves()
	graph_check_tomo_theory()
return 0;

	// PROCESSING
	wave scores, scores_hist, score_bins	
	wave outcome_x, outcome_y, outcome_z 
	wave score_counts_x, score_counts_y, score_counts_z
	//scale_tomo_for_readout_fidelity() // called in feedback_purity
	feedback_purity()
	graph_purity_plot()

	//calculate_arrowOfTime()
end //main


function graph_purity_plot()
	//INPUT
	// run feedback_purity(allData)
	wave outcome_z, outcome_x

	//OUTPUT
	display 
	
	//FUN
	appendTOgraph outcome_z vs outcome_x

end 


function graph_check_tomo_theory()
	// INPUT
	wave corrTomo_z_c, corrTomo_x_c
	wave corrTomo_z_c_err, corrTomo_x_c_err
	wave z_theory, x_theory
	
	//OUTPUT
	display
	
	//FUN
	appendToGraph corrTomo_z_c
	appendToGraph/R/C=(10000,10000,65000) corrTomo_x_c

	appendToGraph/C=(0,0,0) z_theory
	appendToGraph/R/C=(0,0,0) x_theory
	ModifyGraph lstyle(z_theory)=3, lstyle(x_theory)=3
	ErrorBars corrTomo_z_c Y,wave=(corrTomo_z_c_err,corrTomo_z_c_err)
	ErrorBars corrTomo_x_c Y,wave=(corrTomo_x_c_err,corrTomo_x_c_err)
	Legend/C/N=text0/J/A=MC "\\Z16\\s(corrTomo_z_c) Z\r\\s(corrTomo_x_c) X\r\\s(z_theory) theory"	
	
	label left "\Z16<Z>"
	label right "\Z16<X>"
	label bottom "\Z16 V\Bm"
	
end

function calibrate_readout()
	//INPUT
	string file_path = "C:Data:2018:Reversed_Feedback:data_run3:v3_gooder"	
	//string file_path = "Macintosh HD:Users:jmonroe:Documents:research:projects:arrowOfTime_feedback:dataAnalysis:dataSet4"
	//string file_name = "fullData_pi,noPi_81kPnts_f1.5_5420Start_130nsIntegration"
	string file_name = "piNoPi_5420nsStart_145nsIntegration"
	
	//OUTPUT
	variable S, dV //printed to CL
	wave pi_tomo, noPi_tomo
	
	//FUN
	global_variables()
	variable/g sig_min, sig_max, threshold
	
	LoadWave/Q/G/M/D/N=pi_noPiData file_path +":" + file_name
	wave pi_noPiData0, pi_noPiData
	matrixTranspose pi_noPiData0
	duplicate/O pi_noPiData0, pi_noPiData
	
	// parse 3-fold data
	wave pi_wave, noPi_wave
	variable num_samples = dimsize(pi_noPiData0, 0)
	make/o/n=(num_samples/3) pi_wave, noPi_wave
	noPi_wave = pi_noPiData0[0+3*p][0]
	pi_wave = pi_noPiData0[2+3*p][0]
	
	wave pi_wave_str, noPi_wave_str
	make/o/n=(num_samples/3) pi_wave_str, noPi_wave_Str
	noPi_wave_str = pi_noPiData0[0+3*p][1]
	pi_wave_str = pi_noPiData0[2+3*p][1]
	
	// get <z> from pi/noPi
	wave corrTomo, hist_bins
	correlate_tomography(noPi_wave, noPi_wave_str, sig_min, sig_max)
	duplicate/o corrTomo, noPi_tomo
	duplicate/o hist_bins, noPi_tomo_bins
	correlate_tomography(pi_wave, pi_wave_str, sig_min,  sig_max)
	duplicate/o corrTomo, pi_tomo
	duplicate/o hist_bins, pi_tomo_bins
	

	// histogram
	variable num_bins=100
	variable min_bin= wavemin(noPi_wave) //? wavemin(noPi_wave)<wavemin(pi_wave) :wavemin(pi_wave)
	variable max_bin= wavemax(noPi_wave) //? wavemax(noPi_wave)>wavemax(pi_wave) :wavemax(pi_wave)	
	variable bin_size = (max_bin-min_bin)/num_bins
	wave pi_bins_str, noPi_bins_str
	make/o/n=(num_bins) pi_bins, noPi_bins, pi_bins_str, noPi_bins_str
	histogram/B={min_bin,bin_size,num_Bins} noPi_wave, noPi_bins
	histogram/B={min_bin,bin_size,num_Bins} pi_wave, pi_bins

	// fit gaussians
	wave w_coef
	CurveFit/Q gauss pi_bins /D 
	variable sig1=w_coef[3]/sqrt(2), mu1=w_coef[2]
	CurveFit/Q gauss noPi_bins /D 
	variable sig2=w_coef[3]/sqrt(2), mu2=w_coef[2]
	
	// calculate S, dV
	dv = abs(mu1-mu2)
	variable avg_var = (sig1^2 + sig2^2)/2
	S = dV^2/avg_var
	print "S: ", S, "\tdV:", dV
	
	// cleanup
	killwaves pi_noPiData0 
end


function calculate_arrowOfTime()
	//INPUT
	wave weak_signal
	wave z_theory, x_theory
	
	//OUTPUT
	wave log_pf, log_pb, pf_hist, pb_hist
	
	//FUN
	global_variables()
	variable/g num_runs, num_rotations, max_score, min_score, num_bins
	variable/g sig_min, sig_max, threshold
	variable/g dV, S
	variable vm_ex = -172.565, vm_gnd= -175.4 // from calibrate_readout()
	variable score_thresh = 0.1
	variable z0=0, x0=1	
	
	// setup bin
	wave scores, scores_hist, weak_signal
	make/o/n=(num_runs) log_pf, log_pb, good_vm // oversize then redimension
	
//	duplicate/free/o weak_signal scaled_signal
//	variable var = variance(weak_signal)
//	scaled_signal /= sqrt(var *0.25)
//	variable mn = mean(scaled_signal)
//	scaled_signal -= mn	
	
	// calculate probs
	variable i, success_count=0, vm_index, vm
	variable gnd_prob, ex_prob, zf
	for(i=0; i<num_runs; i+=1)
		if (0< scores[i] && scores[i]<1.5)
			vm = weak_signal[i]
			//vm = scaled_signal[i]
			
			// calculate final z
			vm_index = x2pnt( z_theory, weak_signal[i]) // z and x have same scale
			if (vm_index <0)
				vm_index =0
			endif
			if (vm_index >=numpnts(z_theory))
				vm_index = numpnts(z_theory)-1
			endif		
			zf = z_theory[vm_index]

			// calculate probabilties
			gnd_prob = (1+z0)/2 *exp( -(vm - vm_gnd)^2*S/2/dV )
			ex_prob = (1-z0)/2 *exp( -(vm - vm_ex)^2*S/2/dV )
			log_pf[success_count] = ln( gnd_prob + ex_prob)
			
			zf *= 1
			gnd_prob = (1+zf)/2 *exp( -(vm - vm_gnd)^2*S/2/dV )
			ex_prob = (1-zf)/2 *exp( -(vm - vm_ex)^2*S/2/dV )			
			log_pb[success_count] = ln( gnd_prob + ex_prob)
			
			good_vm[success_count] = zf
			success_count +=1
		endif	
	endfor
	redimension/n=(success_count) log_pf, log_pb, good_vm
	make/o/n=(success_count) log_r = log_pf-log_pb
	
	// make histograms
	make/o/n=(num_bins) pf_hist, pb_hist, r_hist, good_vm_hist
	histogram log_pf, pf_hist 
	histogram log_pb, pb_hist 
	histogram log_r, r_hist
	histogram good_vm, good_vm_hist
end //calculate_arrowOfTime


function feedback_purity()
	// calculates expected feedback angle, evaluates "score", calculates agreement
	//INPUT
	wave allData // [num_runs x num_bins+1]
	
	//OUTPUT
	wave scores, scores_hist, score_bins
	wave outcome_x, outcome_y, outcome_z 
	wave score_counts_x, score_counts_y, score_counts_z
		
	//FUN
	global_variables()
	variable/g num_runs, num_rotations, max_score, num_bins

	//chop data
	make/o/n=(num_runs) weak_signal, strong_signal //kwm removed /free
	weak_signal = allData[p][0] 
	strong_signal = allData[p][1]
	
	// setup constants
	wave x_theory, z_theory
	make_theoryCurves()
	make/o/n=(num_rotations) rotations_list //kwm removed /free
	setscale/i x, -pi/4, pi/4, rotations_list
	rotations_list = x

	// Setup predictions for vm_toPred_xyz
	make/o/n=(num_runs) scores	
	variable i
	variable correct_angle, actual_angle
	check_corrTomo(allData) // this needs to be updated for vm_toPred_xyz
	scale_tomo_for_readout_fidelity()
	
	
	// calculate scores
	variable vm_index
	wave predicted_xyz
	wave corrTomo_x, corrTomo_y, corrTomo_z, counts_x
	make/o/n=3 predicted_xyz = {0,0,0}
	variable j
	for (i=0; i<num_runs; i+=1)
		//measurement to x,y,z 
		vm_index = x2pnt( z_theory, weak_signal[i]) // z and x have same scale, KWM: this has 100 points
		if (vm_index <0)
			vm_index =0
		endif
		if (vm_index >=numpnts(z_theory))
			vm_index = numpnts(z_theory)-1
		endif		
		predicted_xyz= {x_theory[vm_index], 0, z_theory[vm_index]}
	//use experimental results (corrTomo) instead of thy:
		//vm_toPred_xyz(weak_signal[i], mod(i,3))

		// evaluate angle
		correct_angle = atan( predicted_xyz[2]/ predicted_xyz[0] )
		actual_angle = rotations_list[ mod(i, num_rotations) ]
		
		// assign score
		scores[i] = abs(correct_angle - actual_angle)
		scores[i] += 1- actual_angle/(pi/4)  // choose high-angles
		
		//scores[i] = correct_angle //KWM testing the angles
		
	
		//scores[i] = predicted_xyz[0] 
	endfor	

	// connect distribution of scores (for each x,y,z) with 
	wave corrTomo, hist_bins
	wave outcome_x, outcome_y, outcome_z 
	wave score_counts_x, score_counts_y, score_counts_z
	make/free/o/n=(num_runs/3) score_subset, proj_subset
	wave sub_block
	//x
	get_subBlock(scores, 0, num_rotations, 3); duplicate/free/o sub_block, score_subset
	get_subBlock(strong_signal, 0, num_rotations, 3); duplicate/free/o sub_block, proj_subset	
	correlate_tomography(score_subset, proj_subset, 0,max_score)
	duplicate/o corrTomo, outcome_x
	outcome_x *= -1 // tomographic pulses bring +x to -z (pi rotation from "top" of Bloch sphere)
	duplicate/o hist_bins, score_counts_x
	//y
	get_subBlock(scores, 1, num_rotations, 3); duplicate/free/o sub_block, score_subset
	get_subBlock(strong_signal, 1, num_rotations, 3); duplicate/free/o sub_block, proj_subset	
	correlate_tomography(score_subset, proj_subset,0,max_score)
	duplicate/o corrTomo, outcome_y
	duplicate/o hist_bins, score_counts_y
	//z
	get_subBlock(scores, 2, num_rotations, 3); duplicate/free/o sub_block, score_subset
	get_subBlock(strong_signal, 2, num_rotations, 3); duplicate/free/o sub_block, proj_subset		
	correlate_tomography(score_subset, proj_subset, 0,max_score)
	duplicate/o corrTomo, outcome_z
	duplicate/o hist_bins, score_counts_z
	//all
	make/o/n=(num_bins) scores_hist, score_bins 
	histogram/b={0, (max_score-0)/num_bins,num_bins} scores, scores_hist
	for (i=0; i<num_bins; i+=1)
		score_bins[i] = pnt2x(scores_hist, i)
	endfor

	 
	// calculate purity
	make/o/n=(num_bins) purity
	for (i=0; i<num_bins; i+=1)
		purity[i] = sqrt( outcome_x[i]^2 + outcome_y[i]^2 + outcome_z[i]^2 )
	endfor	
end //feedback_purity



function get_subBlock(full_list, block_choice_index, block_size, num_blockTypes)
	//INPUT
	wave full_list // list of form [ a1, a2, a3, a4, b1, b2, b3, b4, a5, a6, ... ] 
	variable block_choice_index // select a or b (0 or 1)
	variable block_size // num elem per block (4)
	variable num_blockTypes // here 2
	
	//OUTPUT
	wave sub_block // list of "a_i"
	
	//FUN
	variable num_outputPoints = floor( numpnts(full_list) / (block_size*num_blockTypes) )
	variable section_size = block_size*num_blockTypes
	//  section is list of successive blocks (e.g. up until a5)
	make/o/n=(num_outputPoints) sub_block
	
	variable i, section_index
	for (i=0; i<num_outputPoints; i+=1)
		section_index = floor(i/block_size)*section_size + block_choice_index*block_size
		sub_block[i] = full_list[ section_index +  mod(i,block_size)]	
	endfor	
end //get_subblocks


function vm_toPred_xyz(vm, dim_flag)
	//INPUT
	variable vm
	variable dim_flag // 0=x, 1=y, 2=z
	// generated in check_corrTomo() with scale_tomo_for_readout_fidelity()
	wave counts_x, counts_y, counts_z 
	wave corrTomo_x_c, corrTomo_z_c , corrTomo_y // we don't correct y
	
	//OUTPUT
	make/o/n=3 predicted_xyz
	
	
	//FUN
	// bins for x,y,z are slightly different (?) so id the correct one
	wave curr_bin
	if (dim_flag==0)
		duplicate/o counts_x, curr_bin
	elseif (dim_flag==1)
		duplicate/o counts_y, curr_bin
	else
		duplicate/o counts_z, curr_bin
	endif
	
	// find the right bin
	variable i=0, upper_lim=pnt2x(curr_bin,0)
	do
		i += 1
		upper_lim = pnt2x(curr_bin, i)
	while (vm > upper_lim)
	if (i>=30)
		//print vm, "max", pnt2x(curr_bin, 29)
		i = 29
	endif
	predicted_xyz = {corrTomo_x_c[i], corrTomo_y[i], corrTomo_z_c[i]}
end //vm_toPred_xyz


//function theory_correspondence(allData,t,tau, eta )
//	// double check that the tomographic angle corresponds with vm histogram translated into X,Z
//	// essentially redoing corrTOmo_z vs corrTomo_x without confounding variable of Vm. 
//
//	// A little too out of it atm to think about where this fits in more nicely with everything else
//	
//	//INPUT
//	wave allData
//	variable t, tau, eta
//	variable num_rotations=27	
//	variable num_bins=30
//	
//	//OUTPUT
//	wave theta_vm, theta_tomo, theta_diff, x_diff, z_diff
//
//	// make theta_tomo
//	wave corrTomo_z, corrTomo_x 
//	wave counts_z, counts_x	
//	check_corrTomo(allData)
//	make/o/n=(numpnts(corrTomo_z)) theta_tomo = atan(corrTomo_z/ corrTomo_x)
//
//	make/o/n=(num_bins) theta_tomo_err
//	make/o/n=(num_bins) z_tomo_err, x_tomo_err
//	variable i, zz, xx, pz,px, Nz,Nx, z_err,x_err
//	for (i=0; i<num_bins; i+=1)
//		pz = (corrTomo_z[i]+1)/2; px = (corrTomo_z[i]+1)/2 
//		Nz = counts_z[i]
//		Nx = counts_x[i]
//		z_err = 2*(1.96*sqrt(pz*(1-pz)/Nz)) *0.5 // standard error of <z>
//		x_err = 2*(1.96*sqrt(pz*(1-pz)/Nx)) *0.5 //  = 0.5 * 95% CI
//		
//		theta_tomo_err[i] = xx/(xx^2+zz^2)*z_err - zz/(xx^2+zz^2) *x_err
//		z_tomo_err[i] = z_err
//		x_tomo_err[i] = x_err
//	endfor
//
//	// make theta_vm
//	variable file_length = dimsize(allData,0)
//	variable start_index = 13
//	make/free/o/n=(file_length/num_rotations) weak_signal_zeroAngle
//	weak_signal_zeroAngle = allData[start_index + num_rotations*p][0]	
//	make/o/n=( floor(file_length/num_rotations/3)) x_vm, z_vm
//	//x_vm = weak_signal_zeroAngle[0 + 3*p]
//	
//	//scale signal
//	z_vm = weak_signal_zeroAngle[2 + 3*p] // insensitive to this choice, but use same # points
//	variable var = variance(z_vm), mn = mean(z_vm)
//	z_vm -= mn
//	z_vm /= sqrt(var *0.5)
//	
//	make/o/n=(num_bins) vm_hist, vm_list
//	histogram z_vm vm_hist
//	duplicate/o vm_hist vm_list
//	vm_list = x
//	
//	//variable t=0.13 , tau=0.4, eta=0.32 
//	variable S = 4*t/tau  
//	variable gam = 2* (1-eta)/tau 
//	make/o/n=(num_bins) z_thy, x_thy
//	z_thy = tanh( vm_list[p]*S/4)
//	x_thy = sqrt( 1-z_thy^2) * exp(-gam * t)
//	make/o/n=(num_bins) theta_vm = atan( z_thy / x_thy)	
//	
//	// convert to units of pi
//	theta_vm /= pi
//	theta_tomo /= pi	
//	make/o/n=2 one2one = {wavemin(theta_vm), wavemax(theta_vm)}
//	
//	//graph_thetaCompare()
//	make/o/n=(num_bins) theta_diff = theta_tomo - theta_vm
//	make/o/n=(num_bins) x_diff = corrTomo_x - x_thy
//	make/o/n=(num_bins) z_diff = corrTomo_z - z_thy
//end // theory_correspondence
//
//
//function sweep_error()
//	//INPUT
//	variable num_sweepSteps=21
//	variable eta_min=0.2, eta_max=0.9
//	
//	//OUTPUT
//	wave runningError, eta_sweep
//	make/o/n=(num_sweepSteps) runningError, eta_sweep
//	make/o/n=(num_sweepSteps, 30) full_diff
//	
//	//FUN
//	wave abs_sq_err, theta_diff
//	wave allData
//	make/o/n=(num_sweepSteps) runningError
//	setscale/i x, eta_min, eta_max, eta_sweep
//	eta_sweep = x
//
//	variable i, eta
//	wave x_diff, z_diff, theta_diff
//	for (i=0; i<num_SweepSteps; i+=1)
//		eta = eta_sweep[i]
//		theory_correspondence(allData, 0.130, 0.4, eta)
//		duplicate/o theta_diff, abs_sq_err
//		//abs_sq_err = theta_diff[p]^2
//		abs_sq_err = abs(x_diff[p] )
//		abs_sq_err = numtype(abs_sq_err)==2 ? 0 : abs_sq_err
//		runningError[i] = sum(abs_sq_err)
//		
//		full_diff[i][] = x_diff[q]
//	endfor
//	
//	setscale/i x, eta_min, eta_max, runningError, full_diff
//end //sweep_thetaError


function make_theoryCurves()
		//INPUT
      	variable eta= 0.4      
		variable t2 = 10
		variable f_ramsey=1.5 // units: MHz
		variable chi=0.25*2*Pi, kappa=2.37*2*Pi // units: rad MHz
		variable weak_duration= 0.130, strong_duration= 0.400  // units: us
		variable/g S, dV
  
		variable nbar = f_ramsey/2/chi
		variable gam =  4*chi *f_ramsey*2*Pi *(1-eta)/kappa + 1/t2
		
		print "gam" ,gam
               
       //OUTPUT
       wave z_theory, x_theory

		//CALCULATIONS	
		global_variables()
		variable/g sig_min, sig_max, threshold

		variable num = 100
		make/o/n=(num) x_theory, z_theory    
		setscale/i x, sig_min, sig_max, x_theory, z_theory
		
		variable middle_vm = -172.5
		z_theory = tanh((x- middle_vm)*S/(2*dV))
		x_theory = sqrt(1-z_theory^2) *exp(-gam*weak_duration) 
		duplicate/o z_theory theta_theory
		theta_theory = atan(z_theory/x_theory)
		// duplicate/free/o weak_signal scaled_signal
		// variable var = variance(weak_signal)
		// scaled_signal /= sqrt(var *0.25)
		// variable mn = mean(scaled_signal)
		//	scaled_signal -= mn

//		S = 64*chi^2 *nbar*eta/kappa *t
end //make_theoryCurves


function scale_tomo_for_readout_fidelity()
	//INPUT
	wave corrTomo_x, corrtomo_z, corrTomo_x_err, corrTomo_z_err // from check_corrTomo
	wave pi_tomo, noPi_tomo // from calibrate_Readout
	variable excited_tom_lev = 0.944667 // from average of "well-behaved" region of pi_tomo
	variable gnd_tom_lev = -0.991317 // ... of noPiTomo
	
	//gnd_tom_lev = 0.992869 	// based on data run v2 [3,14]
	//excited_tom_lev = -0.924857 //  ' ' [14,24]
	
	//OUTPUT
	wave corr_tomo_x_c, corr_tomo_z_c, theta_corr_c, corr_Tomo_x_c_err, corr_Tomo_z_c_err
	
	//FUN
	duplicate/o corrTomo_x corrTomo_x_c
	duplicate/o corrTomo_z corrTomo_z_c
	duplicate/o corrTomo_x_err corrTomo_x_c_err
	duplicate/o corrTomo_z_err corrTomo_z_c_err
	duplicate/o pi_tomo pi_tomo_c
	duplicate/o noPi_tomo noPi_tomo_c
	
	variable shift = (excited_tom_lev+gnd_tom_lev)/2
	variable scale = (excited_tom_lev-gnd_tom_lev)/2
	corrTomo_x_c-=shift
	corrTomo_x_c/=scale
	corrTomo_x_c_err /= scale 
	corrTomo_z_c-=shift
	corrTomo_z_c/=scale
	corrTomo_z_c_err /= scale 
	pi_tomo_c-=shift
	pi_tomo_c/=scale
	Nopi_tomo_c-=shift
	NOpi_tomo_c/=scale
	
	duplicate/o Corrtomo_x_c theta_corr_c //kwm changed Corr_tomo_x_c to Corrtomo_x_c
	theta_corr_c = atan(corrtomo_z_c/corrtomo_x_c) //kwm changed Corr_tomo_x_c to Corrtomo_x_c
end // scale_tomo_for_readout_fidelity


function check_corrTomo(allData)
	//TODO: analyze different number of bins
	
	// INPUT
	wave allData // [num_runs x num_bins+1] matrix  (num_bins is weak M, 1 extra is strong M) 
	variable start_index = 12 // 12 steps up from -pi/4 is 0 deg rotation
	
	// OUTPUT
	wave corrTomo_x, corrTomo_y, corrTomo_z
	wave counts_x, counts_y, counts_z
	wave corrTomo_x_err, corrTomo_z_err
		
	//FUN
	global_variables()
	variable/g num_runs, num_rotations, max_score, num_bins
	variable/g sig_min, sig_max, threshold
	
	// CHOP DATA
	//variable file_length = dimsize(allData,0)
	make/free/o/n=(num_runs/num_rotations) weak_signal_zeroAngle, strong_signal_zeroAngle
	weak_signal_zeroAngle = allData[start_index + num_rotations*p][0]
	strong_signal_zeroAngle = allData[start_index + num_rotations*p][1]
	
	make/free/o/n=( floor(num_runs/num_rotations/3)) xs, ys, zs
	xs = weak_signal_zeroAngle[0 + 3*p]
	ys = weak_signal_zeroAngle[1 + 3*p]	
	zs = weak_signal_zeroAngle[2 + 3*p]
	make/free/o/n=( floor(num_runs/num_rotations/3)) strongOut_xs, strongOut_ys, strongOut_zs
	strongOut_xs = strong_signal_zeroAngle[0 + 3*p]
	strongOut_ys = strong_signal_zeroAngle[1 + 3*p]
	strongOut_zs = strong_signal_zeroAngle[2 + 3*p]		
	
	// ANALYZE
	//variable threshold = -172
	wave corrTomo,corrTomo_err,  hist_bins, numtomo
	correlate_tomography(xs, strongOut_xs, sig_min, sig_max)
	duplicate/o corrTomo, corrTomo_x
	corrTOmo_x *= -1 // tomographic pulses bring +x to -z (pi rotation from "top" of Bloch sphere) 
	duplicate/o corrTomo_err, corrTomo_x_err
	duplicate/o hist_bins, counts_x
	
	correlate_tomography(ys, strongOut_ys, sig_min, sig_max)
	duplicate/o corrTomo, corrTomo_y
	duplicate/o hist_bins, counts_y	
	correlate_tomography(zs, strongOut_zs, sig_min, sig_max)
	duplicate/o corrTomo, corrTomo_z
	duplicate/o corrTomo_err, corrTomo_z_err
	duplicate/o hist_bins, counts_z	
end //check_corrTomo


function getavgstate()
wave counts_x, counts_z, corrTomo_z_c, corrtomo_x_c
duplicate/o corrtomo_x_c weightedx, weightedz
weightedx = corrtomo_x_c*counts_x
variable totalx = sum(counts_x)
weightedx = corrtomo_z_c*counts_z
variable totalz = sum(counts_z)
variable avgx = nonansum(weightedx)/totalx
print avgx
variable avgz = nonansum(weightedz)/totalz
print avgz
end

function nonansum(wavein)
wave wavein
variable i
variable sumval=0
for(i=0;i<numpnts(wavein);i+=1)
	if(wavein[i]==nan)

	else
sumval+=wavein[i]
endif
endfor
return sumval
end


function decompose_sequence(allData)
	// recreate AlazarAvg.vi
	//INPUT
	wave allData
	variable num_steps = 81  // 27 steps for 3 angles
	//variable threshold = -173	// look at allData[][0] for good estimate
	
	//OUTPUT
	wave averaged_data
	
	//FUN
	global_variables()
	variable/g num_runs, num_rotations, max_score, num_bins
	variable/g sig_min, sig_max, threshold

	variable num_repeats = floor(num_runs/num_steps)
	
	// extract projection result
	make/free/o/n=(num_runs) strong_outcomes
	strong_outcomes = allData[p][1]
	
	// add thresholded outcomes
	make/o/n=(num_steps) averaged_data=0, counts=0
	redimension/n=(num_steps, num_repeats) strong_outcomes
	variable i,j
	for (i=0; i<num_steps; i+=1)
		for (j=0; j<num_repeats; j+=1)
			averaged_data[i] += sign( threshold - strong_outcomes[i][j] )
			counts[i] += 1
		endfor // end j loop
		averaged_data[i] = averaged_data[i]/counts[i]
	endfor //  end i loop				
end // decompose_sequence


function correlate_tomography(to_hist, strong, hist_bin_First, hist_bin_last)
	//INPUT
	wave to_hist, strong
	variable hist_bin_first, hist_bin_last
	global_variables()
	variable/g num_runs, num_rotations, max_score, num_bins
	variable/g threshold
	
	//OUTPUT
	wave corrTomo, hist_bins, corrTomo_err
	make/o/n=(num_bins) corrTomo =0

	//FUN
	variable first = hist_bin_first, last=hist_bin_last
	make/o/n=(num_bins) hist_bins	, corrTomo_err
	histogram/b={first, abs(last-first)/num_bins, num_bins} to_hist, hist_bins
	setscale/i x, first, last, corrTomo
	duplicate/o corrTomo numTomo
	// connect (correlate) binned outcomes to strong outcomes
	variable bin_min, bin_max, bin_count
	variable num_pnts=numpnts(to_hist)
	variable i,j
	for (i=0; i<num_bins; i+=1)
		bin_min = pnt2x(hist_bins, i)
		bin_max = pnt2x(hist_bins, i+1)
		bin_count=0
		for (j=0; j<num_pnts; j+=1)
			if  ((bin_min < to_hist[j]) * (to_hist[j]< bin_max) ) 
				corrTomo[i] += sign(strong[j]- threshold) // excited state is +1 (for now)
				bin_count += 1
			endif			
		endfor // loop through points
		// normalize counts
		if (bin_count >0)
			corrTomo[i] /= bin_count
			numtomo[i] = bin_count
			
		else
			corrTomo[i] = nan
			numtomo[i] = bin_count
		endif
		// add errors
		variable prob = (corrTomo[i] +1)/2 // expectation value to probability
		// standard error of <z> = 1/2 of 95% CI [see std binomial error]
		corrTomo_err[i] = (1.96 * sqrt(prob*(1-prob)/bin_count))/2
		corrTomo_err[i] *= 2 // convert back to <A>	
	endfor // loop through bins

end // correlate_tomography


function pretty_bloch()
	// A series of adjustments for Bloch sphere graphs
	// Make sure the graph is 'selected'
	
	// adjust axis
	setaxis bottom -1,1; 	setaxis left -1,1
	label bottom "\Z16 <X>"; 	label left "\Z16 <Z>"
	ModifyGraph height={Aspect,1}
	ModifyGraph mode=3,marker=42	
	
	// add circle
	make/o/n=1000 cos_wave, sin_wave
	setscale/i x, 0, 2*Pi, cos_wave, sin_wave
	cos_wave =cos(x)
	sin_wave = sin(x)	
	appendToGraph/C=(0,0,0) sin_wave vs cos_wave
	ModifyGraph mode(sin_wave)=0, lstyle(sin_wave)=3
end //pretty_bloch


//function make_gizmo_from1D(in_array)
//	// decomposes wave into 3 parts and makes Gizmo
//	//INPUT
//	wave in_array
//	
//	//OUTPUT
//	//graphics
//	
//	//FUN
//	variable points_perDim = numpnts(in_array)/3
//	make/o/n=(points_perDim) xs, ys, zs
//	xs = in_array[p]
//	ys = in_array[points_perDim + p]
//	zs = in_array[2*points_perDim + p]	
//
//	wave combined
//	make/o/n=(3, points_perDim) combined
//	combined[0][] = xs[q]
//	combined[1][] = ys[q]
//	combined[2][] = zs[q]
//end // make_gizmo_from1D
//

function do_stuff()
	// junk function for things that can't be done in command line
	wave weak_signal, x_theory, allData
	variable i
	variable num_runs = dimsize(allData,0)
	make/o/n=15000 tmp
	//num_runs = numpnts(weak_signal)
	for (i=0; i<num_runs; i+=1) // 250,000
		variable j = i
		variable vm_index= x2pnt(x_theory,weak_signal[i]) 
		
		
		if (vm_index <0)
			vm_index = 0
		endif
		variable foo = x_theory[mod(vm_index, num_runs)]
//		foo = (numtype(foo) != 2) ? foo : 1
//		tmp[i] = foo

		
	endfor
end

function clean_fileSize()
	killAllWaves(0)
end 


Window graph_thetaCompare() : Graph
	PauseUpdate; Silent 1		// building window...
	Display /W=(75,324,470,532) theta_tomo vs theta_vm
	AppendToGraph one2one vs one2one
	ModifyGraph mode(theta_tomo)=3
	ModifyGraph marker(theta_tomo)=42
	ModifyGraph lStyle(one2one)=3
	ModifyGraph rgb(one2one)=(0,0,0)
	ErrorBars theta_tomo Y,wave=(theta_tomo_err,theta_tomo_err)
	Label bottom "\\Z16\[0 \M?\Bthy\M(V\Bm\M)[p]\]0"
	Label left "\\Z16\[0 ?\B tomo \M[p]\]0"

	Display /W=(74,45,469,253) z_thy vs x_thy
	AppendToGraph corrTomo_z vs corrTomo_x
	ModifyGraph mode=3
	ModifyGraph marker(z_thy)=8
	ModifyGraph rgb(corrTomo_z)=(0,0,0)
	ModifyGraph zmrkSize(z_thy)={vm_hist,*,*,1,10}
	Label left "\\Z16<Z>"
	Label bottom "\\Z16<X>"
	SetAxis left -1,1
	SetAxis bottom -1,1
	Legend/C/N=text0/J/A=MC/X=-20.66/Y=23.18 "\\Z16\r\\s(z_thy) From theory\r\\s(corrTomo_z) From tomo"
EndMacro

Function fit_doubleGaussian(w,x) : FitFunc
	Wave w
	Variable x

	//CurveFitDialog/ These comments were created by the Curve Fitting dialog. Altering them will
	//CurveFitDialog/ make the function less convenient to work with in the Curve Fitting dialog.
	//CurveFitDialog/ Equation:
	//CurveFitDialog/ f(x) = a1*exp( -0.5*(x-mu1)^2/s1^2) + a2*exp( -0.5*(x-mu2)^2/s2^2)  + c
	//CurveFitDialog/ End of Equation
	//CurveFitDialog/ Independent Variables 1
	//CurveFitDialog/ x
	//CurveFitDialog/ Coefficients 7
	//CurveFitDialog/ w[0] = a1
	//CurveFitDialog/ w[1] = a2
	//CurveFitDialog/ w[2] = s1
	//CurveFitDialog/ w[3] = s2
	//CurveFitDialog/ w[4] = mu1
	//CurveFitDialog/ w[5] = mu2
	//CurveFitDialog/ w[6] = c

	return w[0]*exp( -0.5*(x-w[4])^2/w[2]^2) + w[1]*exp( -0.5*(x-w[5])^2/w[3]^2)  + w[6]
End


// replaced with graph_check_tomo_theory()
//Window graph_cf_tomo_thy() : Graph
//	PauseUpdate; Silent 1		// building window...
//	Display /W=(35,45,430,253) z_theory,corrTomo_z
//	ModifyGraph rgb(z_theory)=(0,0,0)
//	ModifyGraph lblMargin(left)=9
//	Label left "\\Z16<Z> (thy or tomo)"
//	Label bottom "\\Z16Vm bin"
//	ErrorBars corrTomo_z Y,wave=(z_tomo_err,z_tomo_err)
//
//	// Z error
//	Display /W=(36,276,431,484) z_diff,zeros
//	ModifyGraph lStyle(zeros)=3
//	ModifyGraph rgb(zeros)=(0,0,0)
//	Label left "\\Z16Thy - tomo"
//	Label bottom "\\Z16Vm bin"
//	SetAxis left -1,0.5
//	ErrorBars z_diff Y,wave=(z_tomo_err,z_tomo_err)
//	
//	// running error
//	Display /W=(39,514,434,722) runningError
//
//	// display x
//	Display /W=(435,45,721,337) x_theory,corrTomo_x
//	ModifyGraph rgb(x_theory)=(0,0,0),rgb(corrTomo_x)=(0,0,65535)
//	Label left "\\Z16<X> (thy or tomo)"
//	Label bottom "\\Z16Vm bin"
//	ErrorBars corrTomo_x Y,wave=(x_tomo_err,x_tomo_err)
//	ModifyGraph swapXY=1
//	// x error
//	Display /W=(496,376,778,710) x_diff,zeros
//	ModifyGraph lStyle(zeros)=3
//	ModifyGraph rgb(x_diff)=(0,0,65535),rgb(zeros)=(0,0,0)
//	Label left "\\Z16Thy - tomo"
//	Label bottom "\\Z16Vm bin"
//	SetAxis left -0.5,0.5
//	ErrorBars x_diff Y,wave=(x_tomo_err,x_tomo_err)
//	ModifyGraph swapXY=1
//	
//	graph_thetaCompare()
//EndMacro
